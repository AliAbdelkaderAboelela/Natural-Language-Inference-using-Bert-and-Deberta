# Natural-Language-Inference-using-Bert-and-Deberta
This project focuses on Natural Language Inference (NLI) using state-of-the-art language models, specifically BERT and DeBERTa. Additionally, the project includes a comprehensive error analysis to understand the models' performance and identify areas for improvement.

## Overview

Natural Language Inference is a fundamental task in natural language processing (NLP) that involves determining the logical relationship between pairs of text segments: a premise and a hypothesis. BERT (Bidirectional Encoder Representations from Transformers) and DeBERTa (Decoding-enhanced BERT with disentangled attention) are powerful pre-trained language models that have shown exceptional performance in various NLP tasks.

## Features

- **NLI Models:** Utilizes BERT and DeBERTa for Natural Language Inference tasks.
- **Error Analysis:** Conducts a thorough analysis of model errors to understand common failure cases and potential areas for improvement.
